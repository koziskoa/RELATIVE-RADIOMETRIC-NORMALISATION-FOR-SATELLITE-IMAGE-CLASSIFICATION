{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3bbebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio             # raster data\n",
    "import rioxarray as rxr     # rasterio with xarray support\n",
    "import xarray as xr         # n-dimenzional data\n",
    "import xvec                 # vector data\n",
    "import pandas as pd         # data manipulation\n",
    "import geopandas as gpd     # geospatial data manipulation\n",
    "\n",
    "import numpy as np              # numerical operations\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "\n",
    "import seaborn as sns                                   # statistical data visualization\n",
    "from sklearn.model_selection import train_test_split    # splitting data into train and test sets\n",
    "from sklearn.ensemble import RandomForestClassifier     # random forest classification\n",
    "from sklearn.model_selection import GridSearchCV        # hyperparameter tuning\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report, f1_score # model evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50842d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and open raster data\n",
    "tiff_file = 'data/imad1Itnew_rescale_SWIR.tif'  \n",
    "rds_imad = rxr.open_rasterio(tiff_file, masked=True).squeeze()\n",
    "print(f'Landsat 9 raster dataset with {rds_imad.shape[0]} bands and {rds_imad.shape[1]} rows and {rds_imad.shape[2]} columns.')\n",
    "\n",
    "# divide bands into separate variables\n",
    "landsat9 = rds_imad.sel(band = [1, 2, 3, 4, 5, 6])\n",
    "landsat5 = rds_imad.sel(band = [7, 8, 9, 10, 11, 12])\n",
    "iamd = rds_imad.sel(band = [13, 14, 15, 16, 17, 18])\n",
    "nc_pix = rds_imad.sel(band = [19])\n",
    "srtm_sl_a = rds_imad.sel(band = [20,21,22])\n",
    "print(f'Dataset consists of {landsat9.shape[0]} bands of Landsat 9, {landsat5.shape[0]} bands of Landsat 5, {iamd.shape[0]} bands of IAMD, \\n{nc_pix.shape[0]} band of NC_Pixels and {srtm_sl_a.shape[0]} bands of SRTM - height, slope, aspect.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ff237f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vector data\n",
    "gdf_l9 = gpd.read_file('data/SHP/l9_Samp_Intersect_new.shp')\n",
    "\n",
    "# drop unneccessary columns\n",
    "un_col = ['FID_Raspol', 'CID', 'FID_Rasp_1', 'Id']\n",
    "gdf_l9 = gdf_l9.drop(columns=un_col)\n",
    "print(f'Point dataset with {gdf_l9.shape[0]} rows and {gdf_l9.shape[1]} columns.')\n",
    "\n",
    "# check nan values\n",
    "print(f'\\nCount of NaN values for L9 data:\\n {gdf_l9.isna().sum()}')\n",
    "# check if there are any duplicates\n",
    "print(f'\\nCount of duplicates for L9 data: {gdf_l9.duplicated().sum()}')\n",
    "\n",
    "info_gdf = gdf_l9\n",
    "type_name = {\n",
    "    1: 'built-up area',\n",
    "    2: 'water',\n",
    "    3: 'forests',\n",
    "    4: 'croplands',\n",
    "    5: 'grasslands',\n",
    "}\n",
    "print(f'\\nCount of unique values for landcover: {info_gdf[\"TYPE\"].nunique()}')\n",
    "info_gdf['TYPE_NAME'] = info_gdf['TYPE'].map(type_name)\n",
    "info_gdf['TYPE_NAME'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b63fb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproject gdf to the same crs as raster\n",
    "gdf_imad_l9 = gdf_l9.to_crs(rds_imad.rio.crs)\n",
    "# check if gdf and raster have the same CRS\n",
    "print(f'Gdf and raster have the same CRS: {gdf_imad_l9.crs == rds_imad.rio.crs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdffbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAD raster data select bands and create a cube\n",
    "invar_pix = rds_imad.sel(band=19)\n",
    "l9_blue = rds_imad.sel(band=1)\n",
    "l9_green = rds_imad.sel(band=2)\n",
    "l9_red = rds_imad.sel(band=3)\n",
    "l9_nir = rds_imad.sel(band=4)\n",
    "l9_swir1 = rds_imad.sel(band=5)\n",
    "l9_swir2 = rds_imad.sel(band=6)\n",
    "\n",
    "l5_blue = rds_imad.sel(band=7)\n",
    "l5_green = rds_imad.sel(band=8)\n",
    "l5_red = rds_imad.sel(band=9)\n",
    "l5_nir = rds_imad.sel(band= 10)\n",
    "l5_swir1 = rds_imad.sel(band=11)\n",
    "l5_swir2 = rds_imad.sel(band=12)\n",
    "\n",
    "iamd_blue = rds_imad.sel(band=13)\n",
    "iamd_green = rds_imad.sel(band=14)\n",
    "iamd_red = rds_imad.sel(band=15)\n",
    "iamd_nir = rds_imad.sel(band=16)\n",
    "iamd_swir1 = rds_imad.sel(band=17)\n",
    "iamd_swir2 = rds_imad.sel(band=18)\n",
    "\n",
    "elevation_imad = rds_imad.sel(band=20)\n",
    "slope_imad = rds_imad.sel(band=21)\n",
    "aspect_imad = rds_imad.sel(band=22)\n",
    "\n",
    "imad_cube = xr.concat(\n",
    "    [l9_blue, l9_green, l9_red, l9_nir, l9_swir1, l9_swir2, l5_blue, l5_green, l5_red, l5_nir, l5_swir1, l5_swir2, iamd_blue, iamd_green, iamd_red, iamd_nir, iamd_swir1, iamd_swir2 , invar_pix, elevation_imad, slope_imad, aspect_imad],\n",
    "    dim=pd.Index(\n",
    "        [\"l9b\", \"l9g\", \"l9r\", \"l9n\", \"l9s1\", \"l9s2\", \"l5b\", \"l5g\", \"l5r\", \"l5n\", \"l5s1\", \"l5s2\", \"ib\", \"ig\", \"ir\", \"in\", \"is1\", \"is2\", \"invar_pix\", \"elevation\", \"slope\", \"aspect\"],\n",
    "        name=\"measurement\",\n",
    "    ) \n",
    ")\n",
    "#imad_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9206459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract raster values to points\n",
    "vector_irmad_cube_l9 = imad_cube.drop_vars(\"spatial_ref\").xvec.extract_points(\n",
    "    points=gdf_imad_l9.geometry,\n",
    "    x_coords=\"x\",\n",
    "    y_coords=\"y\",\n",
    ")\n",
    "vector_irmad_cube_l9\n",
    "\n",
    "# convert to geopandas dataframe\n",
    "gdf_raster_imad_l9 = vector_irmad_cube_l9.xvec.to_geopandas()\n",
    "print(f'Landsat 9 data shape:{gdf_raster_imad_l9.shape}')\n",
    "# sjoin \n",
    "l9_data = gdf_raster_imad_l9.sjoin(gdf_imad_l9[['geometry', 'TYPE']], how=\"left\", predicate=\"intersects\")\n",
    "# dorp index_right column\n",
    "l9_data.drop(columns=\"index_right\", inplace=True)\n",
    "l9_data = l9_data.dropna()\n",
    "l9_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30cd93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply all l5, l9 and i * 100 - for percentage representation (for plotting data)\n",
    "inner_cols = [\"l9b\", \"l9g\", \"l9r\", \"l9n\", \"l9s1\", \"l9s2\",\n",
    "              \"l5b\", \"l5g\", \"l5r\", \"l5n\", \"l5s1\", \"l5s2\",\n",
    "              \"ib\",  \"ig\",  \"ir\",  \"in\",  \"is1\",  \"is2\"]\n",
    "\n",
    "l9_data_df = l9_data.copy()\n",
    "l9_data_df[inner_cols] *= 100\n",
    "l9_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2bb331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Landsat 9 graph\n",
    "# plotting mean spectral curves by landcover\n",
    "l9_spect_bands = ['l5b', 'l5g', 'l5r', 'l5n', 'l5s1', 'l5s2']\n",
    "class_labels = {\n",
    "    1: ('built-up area', 'red'),\n",
    "    2: ('water',    \"blue\"),\n",
    "    3: ('forests', 'green'),\n",
    "    4: ('croplands',   'yellow'),\n",
    "    5: ('grasslands',  '#66c2a5')\n",
    "}\n",
    "\n",
    "for code in l9_data_df['TYPE'].unique():\n",
    "    name, color = class_labels[code]\n",
    "    subset = l9_data_df[l9_data_df['TYPE'] == code]\n",
    "    mean_spect = subset[l9_spect_bands].mean()\n",
    "    plt.plot(l9_spect_bands, mean_spect,\n",
    "             label=name,                  \n",
    "             color=color, linewidth=2)\n",
    "\n",
    "plt.xlabel('band')\n",
    "plt.ylabel('reflectance')\n",
    "plt.title('Mean spectral curves by landuse type')\n",
    "plt.legend(title='Land-use')      \n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72627a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort values by TYPE\n",
    "l9_data = l9_data.sort_values(by='TYPE')\n",
    "#l9_data_df = l9_data_df.sort_values(by='TYPE')\n",
    "count_samples = l9_data['TYPE'].value_counts()\n",
    "count_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822490f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate indices NDVI, NDMI, SAVI, MSAVI, EVI, BSI\n",
    "def ndvi(red, nir):\n",
    "    \"\"\"\n",
    "    Normalized Difference Vegetation Index (NDVI) calculation.\n",
    "    \"\"\"\n",
    "    return (nir - red) / (nir + red)\n",
    "# calculate NDVI\n",
    "l9_data['ndvi9'] = ndvi(l9_data['l9r'], l9_data['l9n'])\n",
    "l9_data['ndvi5'] = ndvi(l9_data['l5r'], l9_data['l5n'])\n",
    "l9_data['ndviI'] = ndvi(l9_data['ir'], l9_data['in'])\n",
    "\n",
    "def ndmi(nir, swir):\n",
    "    \"\"\"\n",
    "    Normalized Difference Moisture Index (NDMI) calculation.\n",
    "    \"\"\"\n",
    "    return (nir - swir) / (nir + swir)\n",
    "# calculate NDMI\n",
    "l9_data['ndmi9'] = ndmi(l9_data['l9n'], l9_data['l9s1'])\n",
    "l9_data['ndmi5'] = ndmi(l9_data['l5n'], l9_data['l5s1'])\n",
    "l9_data['ndmiI'] = ndmi(l9_data['in'], l9_data['is1'])\n",
    "\n",
    "def savi(red, nir):\n",
    "    \"\"\"\n",
    "    Soil Adjusted Vegetation Index (SAVI) calculation.\n",
    "    \"\"\"\n",
    "    L = 0.5  # Soil brightness correction factor\n",
    "    return ((nir - red) * (1 + L) / (nir + red + L)) \n",
    "# calculate SAVI\n",
    "l9_data['savi9'] = savi(l9_data['l9r'], l9_data['l9n'])\n",
    "l9_data['savi5'] = savi(l9_data['l5r'], l9_data['l5n'])\n",
    "l9_data['saviI'] = savi(l9_data['ir'], l9_data['in'])\n",
    "\n",
    "def msavi(red, nir):\n",
    "    \"\"\"\n",
    "    Modified Soil Adjusted Vegetation Index (MSAVI) calculation.\n",
    "    \"\"\"\n",
    "    return (2 * nir + 1 - np.sqrt((2 * nir + 1) ** 2 - 8 * (nir - red))) / 2\n",
    "# calculate MSAVI\n",
    "l9_data['msavi9'] = msavi(l9_data['l9r'], l9_data['l9n'])\n",
    "l9_data['msavi5'] = msavi(l9_data['l5r'], l9_data['l5n'])\n",
    "l9_data['msaviI'] = msavi(l9_data['ir'], l9_data['in'])\n",
    "\n",
    "def evi(blue, red, nir):\n",
    "    \"\"\"\n",
    "    Enhanced Vegetation Index calculation\n",
    "    \"\"\"\n",
    "    G = 2.5     # Gain factor\n",
    "    C1 = 6      # Coefficient for aerosol resistance term\n",
    "    C2 = 7.5    # Coefficient for canopy background adjustment\n",
    "    L = 1       # Canopy background adjustment   \n",
    "    return G * (nir - red) / (nir + C1 * red - C2 * blue + L)\n",
    "# calculate NDBI\n",
    "l9_data['evi9'] = evi(l9_data['l9b'], l9_data['l9r'], l9_data['l9n'])\n",
    "l9_data['evi5'] = evi(l9_data['l5b'], l9_data['l5r'], l9_data['l5n'])\n",
    "l9_data['eviI'] = evi(l9_data['ib'], l9_data['ir'], l9_data['in'])\n",
    "\n",
    "def bsi(blue, red, nir, swir):\n",
    "    \"\"\"\n",
    "    Bare soil index calculation\n",
    "    \"\"\"\n",
    "    return ((blue + swir) - (red - nir)) / ((blue + swir) + (red + nir))\n",
    "l9_data['bsi9'] = bsi(l9_data['l9b'], l9_data['l9r'], l9_data['l9n'], l9_data['l9s1'])\n",
    "l9_data['bsi5'] = bsi(l9_data['l5b'], l9_data['l5r'], l9_data['l5n'], l9_data['l5s1'])\n",
    "l9_data['bsiI'] = bsi(l9_data['ib'], l9_data['ir'], l9_data['in'], l9_data['is1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b213eba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "l9_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d9aee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another spectral bands plots for Landsat 9\n",
    "l9_spect_bands = ['l9b', 'l9g', 'l9r', 'l9n', 'l9s1', 'l9s2']\n",
    "land_names = ['1) Built-up', '2) Water', '3) ForestS', '4) Croplands', '5) Grassland']\n",
    "\n",
    "landcover_types = l9_data['TYPE'].unique() # unique landcover types\n",
    "\n",
    "n_cols = 3 \n",
    "n_rows = 2\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8), squeeze=False)\n",
    "\n",
    "for idx, landcover_type in enumerate(landcover_types):\n",
    "    print(idx, landcover_type)\n",
    "\n",
    "    # calculate row and column index for subplot\n",
    "    row = idx // n_cols \n",
    "    col = idx % n_cols\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    subset = l9_data[l9_data['TYPE'] == landcover_type] # subset data for each landcover type\n",
    "    \n",
    "    # plot each spectral curve - one line = one point\n",
    "    for _, row_data in subset.iterrows():\n",
    "        ax.plot(l9_spect_bands, row_data[l9_spect_bands], alpha=0.2, color='gray')\n",
    "    \n",
    "    # count the mean and std of the each band\n",
    "    mean_spect = subset[l9_spect_bands].mean()\n",
    "    std_spectrum = subset[l9_spect_bands].std()\n",
    "    ax.plot(l9_spect_bands, mean_spect, color='red', linewidth=2, label='mean')\n",
    "    ax.plot(l9_spect_bands, mean_spect - 2*std_spectrum, '--', color='darkred', linewidth=2.5, label='± 2 std')\n",
    "    ax.plot(l9_spect_bands, mean_spect + 2*std_spectrum, '--', color='darkred', linewidth=2.5)\n",
    "    \n",
    "    ax.set_title(f'{land_names[idx]}')\n",
    "    ax.set_xlabel('Band')\n",
    "    ax.set_ylabel('SR')\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "fig.delaxes(axes[1,2]) # remove empty subplot\n",
    "plt.suptitle('Landsat 9 Spectral Curves', fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cc5958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detecting LANDSAT 9 outliers\n",
    "# data copy\n",
    "l9_spect_bands = ['l9b', 'l9g', 'l9r', 'l9n', 'l9s1', 'l9s2']\n",
    "data = l9_data.copy()\n",
    "outlier_indices = [] # list of outlier indices\n",
    "\n",
    "# for each landcover type, calculate the mean and find outliers using RMSE\n",
    "for landcover_type in data['TYPE'].unique():\n",
    "    subset = data[data['TYPE'] == landcover_type]\n",
    "    mean_spect = subset[l9_spect_bands].mean() \n",
    "    \n",
    "    # count the distance of each point from the mean curve (Root Mean Square Error - RMSE)\n",
    "    # RMSE = sqrt(mean((x_i - mean)^2)) -> x_i = each row\n",
    "\n",
    "    dist = np.sqrt(np.mean((subset[l9_spect_bands] - mean_spect)**2, axis=1))\n",
    "    \n",
    "    # threshold - percentile of the distance\n",
    "    # filtering LANDSAT 9 - set 99\n",
    "    # filtering LANDSAT 5 - set 96.5\n",
    "    threshold = np.percentile(dist, 99)\n",
    "    \n",
    "    # find outliers - those points that are above the threshold\n",
    "    outliers = dist[dist > threshold].index # get the index of outliers\n",
    "    outlier_indices.extend(outliers)\n",
    "\n",
    "# print total number of outliers and their indices\n",
    "print(f'Total number of outliers: {len(outlier_indices)}')\n",
    "print('Outlier indices:', outlier_indices)\n",
    "\n",
    "# data copy for next analysis\n",
    "data = l9_data.copy()\n",
    "landcover_types = data['TYPE'].unique()\n",
    "\n",
    "# prepare subplot grid\n",
    "n_cols = 3\n",
    "n_rows = 2\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8), squeeze=False)\n",
    "\n",
    "for idx, landcover_type in enumerate(landcover_types):\n",
    "    row = idx // n_cols \n",
    "    col = idx % n_cols \n",
    "    ax = axes[row, col] \n",
    "    \n",
    "    subset = data[data['TYPE'] == landcover_type] # subset of data for each landcover type \n",
    "    mean_spect = subset[l9_spect_bands].mean() # mean spectral curve of the subset\n",
    "    \n",
    "    for i, (index, row_data) in enumerate(subset.iterrows()):\n",
    "        # plot each spectral curve, if it's an outlier - color it differently\n",
    "        if index in outlier_indices:\n",
    "            ax.plot(l9_spect_bands, row_data[l9_spect_bands], color='orange', alpha=0.7, linewidth=1.5)  \n",
    "        else:\n",
    "            ax.plot(l9_spect_bands, row_data[l9_spect_bands], color='lightgray', alpha=0.3)  \n",
    "    \n",
    "    # plot the mean spectral curve\n",
    "    ax.plot(l9_spect_bands, mean_spect, color='red', linewidth=2, label='mean')\n",
    "    \n",
    "    land_names = ['1) Built-up', '2) Water', '3) Forests', '4) Croplands', '5) Grasslands']\n",
    "    ax.set_title(f'{land_names[idx]}')\n",
    "    ax.set_xlabel('Band')\n",
    "    ax.set_ylabel('SR - rescaled')\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "fig.delaxes(axes[1,2])\n",
    "plt.suptitle('Landsat 9 spectral curves with outliers', fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# clean data from outliers\n",
    "clean_l9_data = data.drop(index=outlier_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df31e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detecting LANDSAT 5 outliers\n",
    "# data copy\n",
    "l5_spect_bands = ['l5b', 'l5g', 'l5r', 'l5n', 'l5s1', 'l5s2']\n",
    "data = clean_l9_data.copy()\n",
    "outlier_indices = [] # list of outlier indices\n",
    "\n",
    "# for each landcover type, calculate the mean and find outliers using RMSE\n",
    "for landcover_type in data['TYPE'].unique():\n",
    "    subset = data[data['TYPE'] == landcover_type]\n",
    "    mean_spect = subset[l5_spect_bands].mean() \n",
    "    \n",
    "    # count the distance of each point from the mean curve (Root Mean Square Error - RMSE)\n",
    "    # RMSE = sqrt(mean((x_i - mean)^2)) -> x_i = each row\n",
    "\n",
    "    dist = np.sqrt(np.mean((subset[l5_spect_bands] - mean_spect)**2, axis=1))\n",
    "    \n",
    "    # threshold - percentile of the distance\n",
    "    threshold = np.percentile(dist, 99)\n",
    "    \n",
    "    # find outliers\n",
    "    outliers = dist[dist > threshold].index # get the index of outliers\n",
    "    outlier_indices.extend(outliers)\n",
    "\n",
    "# print total number of outliers and their indices\n",
    "print(f'Total number of outliers: {len(outlier_indices)}')\n",
    "print('Outlier indices:', outlier_indices)\n",
    "\n",
    "# data copy for next analysis\n",
    "data = clean_l9_data.copy()\n",
    "\n",
    "# type of classes\n",
    "landcover_types = data['TYPE'].unique()\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8), squeeze=False)\n",
    "\n",
    "for idx, landcover_type in enumerate(landcover_types):\n",
    "    row = idx // n_cols\n",
    "    col = idx % n_cols \n",
    "    ax = axes[row, col] \n",
    "    \n",
    "    subset = data[data['TYPE'] == landcover_type] # subset of data for each landcover type \n",
    "    mean_spect = subset[l5_spect_bands].mean() # mean spectral curve of the subset\n",
    "    \n",
    "    for i, (index, row_data) in enumerate(subset.iterrows()):\n",
    "        # plot each spectral curve\n",
    "        if index in outlier_indices:\n",
    "            ax.plot(l5_spect_bands, row_data[l5_spect_bands], color='orange', alpha=0.7, linewidth=1.5)  \n",
    "        else:\n",
    "            ax.plot(l5_spect_bands, row_data[l5_spect_bands], color='lightgray', alpha=0.3)  \n",
    "    \n",
    "    # plot the mean spectral curve\n",
    "    ax.plot(l5_spect_bands, mean_spect, color='red', linewidth=2, label='mean')\n",
    "    \n",
    "    land_names = ['1) Built-up', '2) Water', '3) Forests', '4) Croplands', '5) Grasslands']\n",
    "    ax.set_title(f'{land_names[idx]}')\n",
    "    ax.set_xlabel('Band')\n",
    "    ax.set_ylabel('SR - rescaled')\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "fig.delaxes(axes[1, 2])\n",
    "plt.suptitle('Landsat 5 spectral curves with outliers', fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# clean data from outliers\n",
    "clean_l9_data = data.drop(index=outlier_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e373d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_l9_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a60938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairplot for Landsat 9 / Landsat 5 data\n",
    "pairplot_columns = ['l9b', 'l9g', 'l9r', 'l9n', 'l9s1', 'l9s2', 'l5b', 'l5g', 'l5r', 'l5n', 'l5s1', 'l5s2', 'TYPE']\n",
    "# ['l5b', 'l5g', 'l5r', 'l5n', 'l5s', 'slope', 'ndvi5', 'ndmi5', 'TYPE']\n",
    "\n",
    "sns.pairplot(\n",
    "    clean_l9_data[pairplot_columns],\n",
    "    hue='TYPE',\n",
    "    palette='Set2',\n",
    "    diag_kind='kde',\n",
    "    height=2.5,\n",
    "    aspect=1.2,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d239ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlation\n",
    "corr_col = pairplot_columns[:-1]\n",
    "correlations = clean_l9_data[corr_col + ['TYPE']].corr()['TYPE'].drop('TYPE')\n",
    "\n",
    "# sort correlations by value\n",
    "correlations = correlations.reindex(correlations.abs().sort_values(ascending=False).index)\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3381a093",
   "metadata": {},
   "source": [
    "### PREPARE DATA FOR TRAINING\n",
    "- split data for train, validation and test set\n",
    "    - ensure that sets are stratified\n",
    "- hypertuning using gridsearch\n",
    "- train model\n",
    "    - show most important features\n",
    "- validate model\n",
    "    - count error, show confusion matrix and classification report\n",
    "- classify data with trained model\n",
    "- test model\n",
    "    - count error, show confusion matrix and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccce3ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_l9_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddd9e59",
   "metadata": {},
   "source": [
    "### LANDSAT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e67b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['l5b', 'l5g', 'l5r', 'l5n', 'l5s1', 'l5s2', 'elevation', 'slope', 'aspect', 'ndvi5', 'ndmi5', 'savi5', 'msavi5', 'evi5', 'bsi5'] # features for Landsat 5 data\n",
    "X_l5 = clean_l9_data[features] # not cleaned data: l5_data, cleaned data: clean_l5_data\n",
    "y_l5 = clean_l9_data['TYPE']\n",
    "print(f' dataset count: {X_l5.shape}, y shape: {y_l5.shape}')\n",
    "\n",
    "X_temp_l5, X_test_l5, y_temp_l5, y_test_l5 = train_test_split(X_l5, y_l5, test_size=0.25, random_state=42, stratify=y_l5, shuffle=True) # 0.2\n",
    "X_train_l5, X_valid_l5, y_train_l5, y_valid_l5 = train_test_split(X_temp_l5, y_temp_l5, test_size=0.3333, random_state=42, stratify=y_temp_l5, shuffle=True) # 0.25; 60% train, 20% test, 20% validation\n",
    "\n",
    "# check the sets shapes\n",
    "print(f'For L5 data:\\nTrain dataset shape: {X_train_l5.shape}, Valid dataset shape: {X_valid_l5.shape}, Test dataset shape: {X_test_l5.shape}')\n",
    "#print(f'Train labels shape: {y_train_l5.shape}, Test labels shape: {y_test_l5.shape}\\n')\n",
    "\n",
    "print(\"Train:\\n\", y_train_l5.value_counts(normalize=True))\n",
    "print(\"Valid:\\n\", y_valid_l5.value_counts(normalize=True))\n",
    "print(\"Test:\\n\", y_test_l5.value_counts(normalize=True))\n",
    "\n",
    "# count of each type of training data\n",
    "train_data = pd.concat([X_train_l5, y_train_l5], axis=1)\n",
    "min_samples = train_data['TYPE'].value_counts()\n",
    "min_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31664b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  create new df of clean_l9_data, but just with y_test_l5 rows\n",
    "clean_l5_data_test = clean_l9_data.loc[y_test_l5.index, ['geometry', 'TYPE']] # clean_l9_data, l9_data\n",
    "# we use it in final classification evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69624255",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_range = [1,3, 5, 7, 10, 15, 20]\n",
    "n_estimators = 300 \n",
    "\n",
    "train_errors = []\n",
    "valid_errors = []\n",
    "\n",
    "for d in max_depth_range: # for each max_depth value\n",
    "    rf = RandomForestClassifier(random_state=42,n_estimators=n_estimators, min_samples_split=4, min_samples_leaf=2, max_depth=d, max_features='sqrt', criterion = 'entropy', class_weight='balanced') \n",
    "    \n",
    "    rf.fit(X_train_l5, y_train_l5)\n",
    "    y_train_pred = rf.predict(X_train_l5)\n",
    "    y_valid_pred = rf.predict(X_valid_l5)\n",
    "    \n",
    "    train_error = 1 - accuracy_score(y_train_l5, y_train_pred)\n",
    "    valid_error = 1 - accuracy_score(y_valid_l5, y_valid_pred)\n",
    "\n",
    "    train_errors.append(train_error)\n",
    "    valid_errors.append(valid_error)\n",
    "# plotting train and validation errors\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(max_depth_range, train_errors, label='Train Error', color='salmon')\n",
    "plt.plot(max_depth_range, valid_errors, label='Validation Error', color='cornflowerblue')\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Error (1 − accuracy)')\n",
    "plt.title(f'Train/Test Error by max_depth, n_estimators={n_estimators}')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99946212",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest5 = RandomForestClassifier(random_state=42, min_samples_split=4, min_samples_leaf=2, criterion='entropy', max_features= 'sqrt', class_weight='balanced')\n",
    "\n",
    "# parameters for grid search\n",
    "param_grid = { # Difference between train and test accuracy: 0.0563 for balanced data\n",
    "    'n_estimators': [50, 100, 150, 200, 250, 300],   # numeber of trees\n",
    "    'max_depth': [5, 7, 10, 15, 20],   # maximum depth of the tree\n",
    "    # 'max_features': [4, 5, 7, 8, 9] # number of features to consider for the best split\n",
    "    # 'scriterion': ['gini', 'entropy'], # criterion for splitting\n",
    "    # 'max_features': ['sqrt', 'log2'], # number of features to consider for the best split\n",
    "}    \n",
    "# grid search definition\n",
    "gs = GridSearchCV(estimator=forest5, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "\n",
    "# run grid search\n",
    "gs.fit(X_train_l5, y_train_l5)\n",
    "# get df from best_parameters\n",
    "best_params = pd.DataFrame(gs.cv_results_).sort_values(by='rank_test_score')\n",
    "best_params = best_params[['params', 'mean_test_score', 'std_test_score', 'rank_test_score']]\n",
    "\n",
    "# get best parameters\n",
    "print(\"Best parameters from GridSearch:\")\n",
    "print(gs.best_params_)\n",
    "best_params.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47be567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = RandomForestClassifier(random_state=42, n_estimators=100, max_depth=15, min_samples_split=4, min_samples_leaf=2, max_features='sqrt', criterion = 'entropy', class_weight='balanced') # min_samples_split=10, min_samples_leaf=12\n",
    "l5_model = best_rf.fit(X_train_l5, y_train_l5) \n",
    "\n",
    "# Train model on the balanced training set\n",
    "y_train_pred = l5_model.predict(X_train_l5) \n",
    "\n",
    "# training accuracy and error\n",
    "train_accuracy = accuracy_score(y_train_l5, y_train_pred) \n",
    "train_error = 1 - train_accuracy\n",
    "\n",
    "# feature importances\n",
    "importances = pd.Series(l5_model.feature_importances_, index=X_train_l5.columns).sort_values(ascending=False) \n",
    "\n",
    "print(\"\\nFeature Importances:\")\n",
    "print(f'{importances}\\n')\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Training Error: {train_error:.4f}\")\n",
    "\n",
    "y_valid_pred = l5_model.predict(X_valid_l5)\n",
    "\n",
    "# test accuracy and test error\n",
    "valid_accuracy = accuracy_score(y_valid_l5, y_valid_pred)\n",
    "valid_error = 1 - valid_accuracy\n",
    "\n",
    "print(f\"Validation Accuracy: {valid_accuracy:.4f}\")\n",
    "print(f\"Validation Error: {valid_error:.4f}\\n\")\n",
    "\n",
    "# is model well trained? - we can count the difference between train and test accuracy\n",
    "train_val_diff = train_accuracy - valid_accuracy\n",
    "print(f\"Difference between train and validation accuracy: {train_val_diff:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf820c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm count\n",
    "l5_c_matrix = confusion_matrix(y_valid_l5, y_valid_pred)\n",
    "# confusion matrix\n",
    "class_names = ['built-up', 'water', 'forests', 'croplands', 'grasslands']\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=l5_c_matrix, display_labels=class_names)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "disp.plot(ax=ax, cmap='Blues', colorbar=False, xticks_rotation=20)\n",
    "plt.title('Confusion Matrix - Landsat 5')\n",
    "plt.show()\n",
    "\n",
    "# classification report\n",
    "report = classification_report(y_valid_l5, y_valid_pred, target_names=[str(cls) for cls in np.unique(y_valid_l5)])\n",
    "print(\"Classification Report:\")\n",
    "print(report)# cm count\n",
    "l5_c_matrix = confusion_matrix(y_valid_l5, y_valid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff4cec7",
   "metadata": {},
   "source": [
    "- <b>Precision</b> = TP / (TP + FP) → kolik predikcí je správných\n",
    "\n",
    "- <b>Recall</b> = TP / (TP + FN) → kolik správných případů jsme zachytili\n",
    "\n",
    "- <b>F1-Score</b> = 2 * (Precision * Recall) / (Precision + Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd78228",
   "metadata": {},
   "source": [
    "#### LANDSAT 5 CLASIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7386531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function for reshaping the data for classification\n",
    "def reshape_data(raster_data):\n",
    "    bands, height, width = raster_data.shape\n",
    "    reshaped_data = raster_data.reshape(bands, -1).T # (height * width, bands)\n",
    "    return reshaped_data, height, width # (height * width, bands)\n",
    "\n",
    "# create function for converting the data into DataFrame\n",
    "def create_dataframe(reshaped_data):  # , profile\n",
    "    # create DataFrame from the reshaped data\n",
    "    df = pd.DataFrame(reshaped_data, columns=[f'band_{i}' for i in range(reshaped_data.shape[1])])\n",
    "    return df\n",
    "\n",
    "with rasterio.open('data/imad1Itnew_rescale_SWIR.tif') as src: # data/imad1Itnew_rescale_SWIR.tif\n",
    "    image = src.read()  # tvar: (bands, height, width)\n",
    "    profile = src.profile\n",
    "print(f'image shape: {image.shape}')\n",
    "print(f'profile: {profile}')\n",
    "\n",
    "# Landsat 5 bands\n",
    "landsat5_selected = image[6:12, :, :] # Landsat 5 bands \n",
    "srtm_selected = image[19:22, :, :] # SRTM, slope, aspect\n",
    "\n",
    "print(f'Landsat 5 bands shape: {landsat5_selected.shape}')\n",
    "print(f'SRTM bands shape: {srtm_selected.shape}')\n",
    "landsat5_bands = np.concatenate([landsat5_selected, srtm_selected], axis=0)\n",
    "print(f'final_stack shape: {landsat5_bands.shape}')\n",
    "\n",
    "reshaped_l5, height_l9, width_l9= reshape_data(landsat5_bands)\n",
    "df_l5 = create_dataframe(reshaped_l5)\n",
    "print(f'Landsat 5 DataFrame shape: {df_l5.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f44ad63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mask for NaN values\n",
    "columns_to_replace = ['band_0', 'band_1', 'band_2', 'band_3', 'band_4', 'band_5', 'band_6']\n",
    "nan_mask = df_l5[columns_to_replace].isna()\n",
    "df_l5[columns_to_replace] = df_l5[columns_to_replace].fillna(99999)\n",
    "print(f'max val for slope and aspect: \\n{df_l5[['band_7', 'band_8']].max()}')\n",
    "print(f'min val for slope and aspect: \\n{df_l5[['band_7', 'band_8']].min()}')\n",
    "print(f'median val for slope and aspect: \\n{df_l5[['band_7', 'band_8']].median()}')\n",
    "# if band_7 or band_8 are NaN values, set them to 0\n",
    "df_l5['band_7'] = df_l5['band_7'].fillna(0)\n",
    "df_l5['band_8'] = df_l5['band_8'].fillna(0)\n",
    "columns = ['l5b', 'l5g', 'l5r', 'l5n', 'l5s1', 'l5s2', 'elevation', 'slope', 'aspect']\n",
    "# rename columns for landsat 5\n",
    "df_l5.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8099a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating ndvi5, ndmi 5, savi5, msavi5, evi5, bsi5\n",
    "df_l5['ndvi5'] = ndvi(df_l5['l5r'], df_l5['l5n'])\n",
    "df_l5['ndmi5'] = ndmi(df_l5['l5n'], df_l5['l5s1'])\n",
    "df_l5['savi5'] = savi(df_l5['l5r'], df_l5['l5n'])\n",
    "df_l5['msavi5'] = msavi(df_l5['l5r'], df_l5['l5n'])\n",
    "df_l5['evi5'] = evi(df_l5['l5b'], df_l5['l5r'], df_l5['l5n'])\n",
    "df_l5['bsi5'] = bsi(df_l5['l5b'], df_l5['l5r'], df_l5['l5n'], df_l5['l5s1'])\n",
    "df_l5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f774005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for invalid values\n",
    "bad_mask = ~np.isfinite(df_l5).all(axis=1)    \n",
    "print(f\"invalid rows count: {bad_mask.sum()}\")\n",
    "df_l5.replace([np.inf, -np.inf, 99999], 99999.0, inplace=True)     \n",
    "bad_mask = ~np.isfinite(df_l5).all(axis=1)    \n",
    "print(f\"invalid rows count: {bad_mask.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c568eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_l5 = df_l5.values\n",
    "y_pred_l5 = l5_model.predict(X_l5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e20e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_raster_l5 = y_pred_l5.reshape(height_l9, width_l9).astype(rasterio.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeb0898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the prediction raster\n",
    "output_file = 'data/l5_pred_new.tif'\n",
    "with rasterio.open(output_file, 'w', driver='GTiff', height=height_l9, width=width_l9, count=1, dtype=rasterio.uint16, crs=profile['crs'], transform=profile['transform']) as dst:\n",
    "    dst.write(prediction_raster_l5, 1)\n",
    "    dst.update_tags(landcover_type='Landsat 5', classifier = 'Random Forest', classes='1=Built-up, 2=Water, 3=Forest, 4=Cropland, 5=Grassland') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dceac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(prediction_raster_l5, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f'Class {label}: {count} px')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c5d538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "class_labels = {\n",
    "    1: ('built-up areas', 'red'),    \n",
    "    2: ('water', 'blue'),       \n",
    "    3: ('forests', 'green'),       \n",
    "    4: ('croplands', 'yellow'),     \n",
    "    5: ('grasslands', '#66c2a5')     \n",
    "}\n",
    "\n",
    "cmap_list = [class_labels[i][1] for i in range(1, 6)]\n",
    "cmap = ListedColormap(cmap_list)\n",
    "crop = 3                                    \n",
    "pred_crop = prediction_raster_l5[1:-crop, 4:-4]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "im = ax.imshow(pred_crop, cmap=cmap, interpolation='nearest') # \n",
    "ax.set_title('Landsat 5 classification (Random Forest)', fontsize=16)\n",
    "#ax.set_xlabel('Pixel (X)', fontsize=12)\n",
    "#ax.set_ylabel('Pixel (Y)', fontsize=12)\n",
    "ax.axis('off')\n",
    "ax.grid(False)\n",
    "# legend\n",
    "legend_patches = [mpatches.Patch(color=color, label=label) for label, color in [class_labels[i] for i in range(1, 6)]]\n",
    "ax.legend(handles=legend_patches, loc='lower center', bbox_to_anchor=(0.5, -0.06), ncol=5, fontsize=12, frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd59ae7",
   "metadata": {},
   "source": [
    "#### L5 Classification evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b50062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open('data/l5_pred.tif') as src:\n",
    "    class_l5 = src.read(1)  # load the first band - classification band\n",
    "    profile = src.profile\n",
    "# close file\n",
    "tiff_file = 'data/l5_pred.tif' \n",
    "with rxr.open_rasterio(tiff_file, masked=True).squeeze() as class_l5:\n",
    "    class_l5 = class_l5.squeeze()  # remove single-dimensional entries from the shape of an array\n",
    "    print(f'Landsat 5 classification raster shape: {class_l5.shape}')\n",
    "    #print(class_l5)\n",
    "gdf_class_l5 = gdf_imad_l9.to_crs(class_l5.rio.crs)\n",
    "print(f'Same CRS: {gdf_class_l5.crs == class_l5.rio.crs}')  # check if CRS are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6368b660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column with 15 raster values\n",
    "class_cube = xr.concat(\n",
    "    [class_l5],\n",
    "    dim=pd.Index(\n",
    "        [\"class_l5\"],\n",
    "        name=\"measurement\",\n",
    "    )\n",
    ")\n",
    "class_cube\n",
    "vector_class_cube_l5 = class_cube.drop_vars(\"spatial_ref\").xvec.extract_points(\n",
    "    points=gdf_imad_l9.geometry,\n",
    "    x_coords=\"x\",\n",
    "    y_coords=\"y\",\n",
    ")\n",
    "\n",
    "gdf_imad_l9.isna().sum() \n",
    "gdf_class_l5= vector_class_cube_l5.xvec.to_geopandas()\n",
    "print(f'Landsat class 5 data shape:{gdf_class_l5.shape}')\n",
    "\n",
    "# sjoin\n",
    "class_comp_l5 = gdf_class_l5.sjoin(clean_l9_data[['geometry', 'TYPE']], predicate=\"intersects\") \n",
    "# dorp index_right column\n",
    "class_comp_l5.drop(columns=\"index_right\", inplace=True)\n",
    "class_comp_l5 = class_comp_l5.dropna()\n",
    "\n",
    "#clean_l5_data_test -filter test data \n",
    "l5_class_filtered = class_comp_l5.loc[clean_l5_data_test.index]\n",
    "l5_class_filtered.sort_index(inplace=True)\n",
    "l5_class_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99df1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how well the raster classification matches the vector data\n",
    "test_accuracy = accuracy_score(l5_class_filtered['TYPE'], l5_class_filtered['class_l5'])\n",
    "test_error = 1 - test_accuracy\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Error: {test_error:.4f}\")\n",
    "\n",
    "# count producer's accuracy\n",
    "producer_accuracy = l5_class_filtered.groupby('TYPE').apply(lambda x: (x['class_l5'] == x['TYPE']).sum() / len(x))\n",
    "print(\"Producer's Accuracy:\")\n",
    "print(producer_accuracy)\n",
    "# count user's accuracy\n",
    "user_accuracy = l5_class_filtered.groupby('class_l5').apply(lambda x: (x['class_l5'] == x['TYPE']).sum() / len(x))\n",
    "print(\"User's Accuracy:\")\n",
    "print(user_accuracy)\n",
    "# confusion matrix\n",
    "class_names = ['built-up', 'water', 'forests', 'croplands', 'grasslands']\n",
    "l9_c_matrix = confusion_matrix(l5_class_filtered['TYPE'], l5_class_filtered['class_l5'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=l9_c_matrix, display_labels=class_names)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "disp.plot(ax=ax, cmap='Blues', colorbar=False, xticks_rotation=20)\n",
    "plt.title('Confusion Matrix for Landsat 5')\n",
    "plt.show()\n",
    "\n",
    "# classification report\n",
    "report = classification_report(l5_class_filtered['TYPE'], l5_class_filtered['class_l5'], target_names=[str(cls) for cls in np.unique(l5_class_filtered['TYPE'])])\n",
    "print(\"Classification Report for Landsat 5:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93e8efe",
   "metadata": {},
   "source": [
    "### LANDSAT 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dfd493",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['l9b', 'l9g', 'l9r', 'l9n', 'l9s1', 'l9s2', 'elevation', 'slope', 'aspect', 'ndvi9', 'ndmi9', 'savi9', 'msavi9', 'evi9', 'bsi9'] # features for Landsat 9 data  , 'ndvi9', 'ndmi9', 'savi9', 'msavi9', 'evi9', 'bsi9'\n",
    "X_l9 = clean_l9_data[features] # not cleaned data: l9_data, cleaned data: clean_l9_data\n",
    "y_l9 = clean_l9_data['TYPE']\n",
    "print(f' dataset count: {X_l9.shape}, y shape: {y_l9.shape}')\n",
    "\n",
    "X_temp_l9, X_test_l9, y_temp_l9, y_test_l9 = train_test_split(X_l9, y_l9, test_size=0.25, random_state=42, stratify=y_l9, shuffle=True) # 0.2\n",
    "X_train_l9, X_valid_l9, y_train_l9, y_valid_l9 = train_test_split(X_temp_l9, y_temp_l9, test_size=0.3333, random_state=42, stratify=y_temp_l9, shuffle=True) # 0.25; 60% train, 20% test, 20% validation\n",
    "\n",
    "# check the sets shapes\n",
    "print(f'For L5 data:\\nTrain dataset shape: {X_train_l9.shape}, Valid dataset shape: {X_valid_l9.shape}, Test dataset shape: {X_test_l9.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3f3df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train:\\n\", y_train_l9.value_counts(normalize=True))\n",
    "print(\"Valid:\\n\", y_valid_l9.value_counts(normalize=True))\n",
    "print(\"Test:\\n\", y_test_l9.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0661a983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the distribution of the classes\n",
    "y_test_l9.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6587e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of each type of training data\n",
    "train_data = pd.concat([X_train_l9, y_train_l9], axis=1)\n",
    "min_samples = train_data['TYPE'].value_counts()\n",
    "min_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3c9b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  create new df of clean_l9_data, but just with y_test_l9 rows\n",
    "clean_l9_data_test = clean_l9_data.loc[y_test_l9.index, ['geometry', 'TYPE']] # clean_l9_data, l9_data\n",
    "# we use it in final classification consideration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54271c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_range = [1,3, 5, 7, 10, 15, 20]\n",
    "n_estimators = 300\n",
    "\n",
    "train_errors = []\n",
    "valid_errors = []\n",
    "\n",
    "for d in max_depth_range:\n",
    "    rf = RandomForestClassifier(random_state=42,n_estimators=n_estimators, min_samples_split=4, min_samples_leaf=2, max_depth=d, max_features=8, criterion = 'log_loss', class_weight='balanced') \n",
    "    \n",
    "    rf.fit(X_train_l9, y_train_l9)\n",
    "    y_train_pred = rf.predict(X_train_l9)\n",
    "    y_valid_pred = rf.predict(X_valid_l9)\n",
    "    # count train and valid errors\n",
    "    train_error = 1 - accuracy_score(y_train_l9, y_train_pred)\n",
    "    valid_error = 1 - accuracy_score(y_valid_l9, y_valid_pred)\n",
    "\n",
    "    train_errors.append(train_error)\n",
    "    valid_errors.append(valid_error)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(max_depth_range, train_errors, label='Train Error', color='salmon')\n",
    "plt.plot(max_depth_range, valid_errors, label='Validation Error', color='cornflowerblue')\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Chyba (1 − accuracy)')\n",
    "plt.title(f'Train/Test Error by max_depth, n_estimators={n_estimators}')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721e937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest definition\n",
    "forest9 = RandomForestClassifier(random_state=42, min_samples_split=4, min_samples_leaf=2, max_features= 'sqrt', criterion = 'entropy', class_weight='balanced') # \n",
    "\n",
    "# parameters for grid search\n",
    "param_grid = { \n",
    "    'n_estimators': [50, 100, 150, 200, 250, 300],   # number of trees\n",
    "    'max_depth': [5, 7, 10, 15, 20, 25, 30],   # maximum depth of the tree\n",
    "    # 'max_features': [4, 5, 7, 8, 9] # number of features to consider for the best split\n",
    "    # 'scriterion': ['gini', 'entropy'], # criterion for splitting\n",
    "    # 'max_features': ['sqrt', 'log2'], # number of features to consider for the best split\n",
    "}    \n",
    "\n",
    "# grid search definition\n",
    "gs = GridSearchCV(estimator=forest9, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "\n",
    "# run grid search\n",
    "gs.fit(X_train_l9, y_train_l9)\n",
    "# get df from best_parameters\n",
    "best_params = pd.DataFrame(gs.cv_results_).sort_values(by='rank_test_score')\n",
    "best_params = best_params[['params', 'mean_test_score', 'std_test_score', 'rank_test_score']]\n",
    "\n",
    "# get best parameters\n",
    "print(\"Best parameters from GridSearch:\")\n",
    "print(gs.best_params_)\n",
    "best_params.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056f7491",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = RandomForestClassifier(random_state=42, n_estimators=200, max_depth=10, min_samples_split=4, min_samples_leaf=2, max_features='sqrt', criterion = 'entropy', class_weight='balanced') # min_samples_split=10, min_samples_leaf=12\n",
    "l9_model = best_rf.fit(X_train_l9, y_train_l9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba7959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model on the balanced training set\n",
    "y_train_pred = l9_model.predict(X_train_l9) \n",
    "\n",
    "# training accuracy and error\n",
    "train_accuracy = accuracy_score(y_train_l9, y_train_pred) \n",
    "train_error = 1 - train_accuracy\n",
    "\n",
    "# feature importances\n",
    "importances = pd.Series(l9_model.feature_importances_, index=X_train_l9.columns).sort_values(ascending=False) \n",
    "\n",
    "print(\"\\nFeature Importances:\")\n",
    "print(f'{importances}\\n')\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Training Error: {train_error:.4f}\")\n",
    "y_valid_pred = l9_model.predict(X_valid_l9)\n",
    "\n",
    "# test accuracy and test error\n",
    "valid_accuracy = accuracy_score(y_valid_l9, y_valid_pred)\n",
    "valid_error = 1 - valid_accuracy\n",
    "\n",
    "print(f\"Validation Accuracy: {valid_accuracy:.4f}\")\n",
    "print(f\"Validation Error: {valid_error:.4f}\\n\")\n",
    "\n",
    "# is model well trained? - we can count the difference between train and test accuracy\n",
    "train_val_diff = train_accuracy - valid_accuracy\n",
    "print(f\"Difference between train and validation accuracy: {train_val_diff:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ac84c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "l9_model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c1d0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm count\n",
    "l9_c_matrix = confusion_matrix(y_valid_l9, y_valid_pred)\n",
    "# confusion matrix\n",
    "class_names = ['built-up', 'water', 'forests', 'croplands', 'grasslands']\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=l9_c_matrix, display_labels=class_names) # np.unique(y_valid_l9)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "#ax.tick_params(axis='x', labelrotation=45)\n",
    "disp.plot(ax=ax, cmap='Blues', colorbar=False, xticks_rotation=20)\n",
    "plt.title('Confusion Matrix - Landsat 9')\n",
    "plt.show()\n",
    "\n",
    "# classification report\n",
    "report = classification_report(y_valid_l9, y_valid_pred, target_names=[str(cls) for cls in l9_model.classes_], )\n",
    "print(\"Classification Report:\")\n",
    "print(report)# cm count\n",
    "l9_c_matrix = confusion_matrix(y_valid_l9, y_valid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdbe769",
   "metadata": {},
   "source": [
    "### Raster data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240b8625",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open('data/imad1Itnew_rescale_SWIR.tif') as src: # data/imadMaxItnew_rescale_SWIR.tif, kompozity: data/imad5Itnew_colab_01_composite_mode.tif\n",
    "    image = src.read()  # shape: (bands, height, width)\n",
    "    profile = src.profile\n",
    "print(f'image shape: {image.shape}')\n",
    "print(f'profile: {profile}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be337e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the image\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image[9], cmap='gray')\n",
    "plt.title('IRMAD Image - Band NIR')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b6c017",
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat9_selected = image[0:6, :, :] # Landsat 5 bands \n",
    "srtm_selected = image[19:22, :, :] # SRTM, slope, aspect\n",
    "'''indices_selected = np.stack([ # indices ndvi and ndmi - bands 22,23,26,27 \n",
    "    image[23, :, :], # ndvi9\n",
    "    image[24, :, :] # ndmi9\n",
    "], axis=0)'''\n",
    "\n",
    "print(f'Landsat 5 bands shape: {landsat9_selected.shape}')\n",
    "print(f'SRTM bands shape: {srtm_selected.shape}')\n",
    "#print(f'Indices bands shape: {indices_selected.shape}')\n",
    "landsat9_bands = np.concatenate([landsat9_selected, srtm_selected], axis=0) # , indices_selected\n",
    "print(f'final_stack shape: {landsat9_bands.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7612614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function for reshaping the data for classification\n",
    "def reshape_data(raster_data):\n",
    "    bands, height, width = raster_data.shape\n",
    "    # reshape the data to 2D array\n",
    "    # data shape (bands, height, width) to (height * width, bands)\n",
    "    reshaped_data = raster_data.reshape(bands, -1).T # (height * width, bands)\n",
    "    return reshaped_data, height, width # (height * width, bands)\n",
    "\n",
    "# create function for converting the data into DataFrame\n",
    "def create_dataframe(reshaped_data):  # , profile\n",
    "    # create DataFrame from the reshaped data\n",
    "    df = pd.DataFrame(reshaped_data, columns=[f'band_{i}' for i in range(reshaped_data.shape[1])])\n",
    "    # add the profile information to the DataFrame\n",
    "    # df['x'] = np.repeat(np.arange(profile['width']), profile['height'])\n",
    "    # df['y'] = np.tile(np.arange(profile['height']), profile['width'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eece8eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape l5, l9 and irmad data for classification\n",
    "reshaped_l9, height_l9, width_l9 = reshape_data(landsat9_bands)\n",
    "#reshaped_l9, height_l9, width_l9 = reshape_data(landsat9_bands)\n",
    "#reshaped_irmad, height_im, width_im = reshape_data(irmad_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aded4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to DataFrame\n",
    "df_l9 = create_dataframe(reshaped_l9)\n",
    "#df_l9 = create_dataframe(reshaped_l9)\n",
    "#df_irmad = create_dataframe(reshaped_irmad)\n",
    "\n",
    "# check the shape of the DataFrames\n",
    "print(f'Landsat 9 DataFrame shape: {df_l9.shape}')\n",
    "#print(f'Landsat 9 DataFrame shape: {df_l9.shape}')\n",
    "#print(f'IRMAD DataFrame shape: {df_irmad.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6f78fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0a19f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_replace = ['band_0', 'band_1', 'band_2', 'band_3', 'band_4', 'band_5', 'band_6']\n",
    "nan_mask = df_l9[columns_to_replace].isna()\n",
    "df_l9[columns_to_replace] = df_l9[columns_to_replace].fillna(99999)\n",
    "nan_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc555e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597c8f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check values for band_6 and band_7\n",
    "print(f'max val for slope and aspect: \\n{df_l9[['band_7', 'band_8']].max()}')\n",
    "print(f'min val for slope and aspect: \\n{df_l9[['band_7', 'band_8']].min()}')\n",
    "print(f'median val for slope and aspect: \\n{df_l9[['band_7', 'band_8']].median()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe32946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if band_6 and band_7 are NaN values, set them to 0\n",
    "df_l9['band_7'] = df_l9['band_7'].fillna(0)\n",
    "df_l9['band_8'] = df_l9['band_8'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eb40f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94fe9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['l9b', 'l9g', 'l9r', 'l9n', 'l9s1', 'l9s2', 'elevation', 'slope', 'aspect']\n",
    "# rename columns for landsat 5\n",
    "df_l9.columns = columns\n",
    "# check the shape of the DataFrame\n",
    "df_l9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cc5ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating ndvi9, ndmi9, savi9, msavi9, ndbi9, bsi9\n",
    "df_l9['ndvi9'] = ndvi(df_l9['l9r'], df_l9['l9n'])\n",
    "# calculate NDMI for Landsat 9\n",
    "df_l9['ndmi9'] = ndmi(df_l9['l9n'], df_l9['l9s1'])\n",
    "\n",
    "df_l9['savi9'] = savi(df_l9['l9r'], df_l9['l9n'])\n",
    "# calculate MSAVI for Landsat 9\n",
    "df_l9['msavi9'] = msavi(df_l9['l9r'], df_l9['l9n'])\n",
    "# calculate EVI for Landsat 9\n",
    "df_l9['evi9'] = evi(df_l9['l9b'], df_l9['l9r'], df_l9['l9n'])\n",
    "\n",
    "# calculate BSI for Landsat 9\n",
    "df_l9['bsi9'] = bsi(df_l9['l9b'], df_l9['l9r'], df_l9['l9n'], df_l9['l9s1'])\n",
    "df_l9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647bdae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inf/-inf/NaN\n",
    "bad_mask = ~np.isfinite(df_l9).all(axis=1)    \n",
    "print(f\"invalid rows count: {bad_mask.sum()}\")\n",
    "df_l9.replace([np.inf, -np.inf, 99999], 99999.0, inplace=True)\n",
    "#X_clean = X_l9.dropna()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccb58f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_mask = ~np.isfinite(df_l9).all(axis=1)    \n",
    "print(f\"invalid rows count: {bad_mask.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac03cda3",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd3c437",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_l9 = df_l9#.values\n",
    "y_pred_l9 = l9_model.predict(X_l9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05e5562",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_raster_l9 = y_pred_l9.reshape(height_l9, width_l9).astype(rasterio.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b765aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the prediction raster\n",
    "output_file = 'data/l9_pred.tif'\n",
    "with rasterio.open(output_file, 'w', driver='GTiff', height=height_l9, width=width_l9, count=1, dtype=rasterio.uint16, crs=profile['crs'], transform=profile['transform']) as dst:\n",
    "    dst.write(prediction_raster_l9, 1)\n",
    "    dst.update_tags(landcover_type='Landsat 9', classifier = 'Random Forest', classes='1=Built-up, 2=Water, 3=Forest, 4=Cropland, 5=Grassland') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ecb26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(prediction_raster_l9, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f'Class {label}: {count} px')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bad296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "class_labels = {\n",
    "    1: ('built-up areas', 'red'),    \n",
    "    2: ('water', 'blue'),       \n",
    "    3: ('forests', 'green'),       \n",
    "    4: ('croplands', 'yellow'),     \n",
    "    5: ('grasslands', '#66c2a5')     \n",
    "}\n",
    "pred_crop = prediction_raster_l9[1:-3, 4:-4]\n",
    "\n",
    "cmap_list = [class_labels[i][1] for i in range(1, 6)]\n",
    "cmap = ListedColormap(cmap_list)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "im = ax.imshow(pred_crop, cmap=cmap, interpolation='nearest')\n",
    "ax.set_title('Landsat 9 classification (Random Forest)', fontsize=16)\n",
    "#ax.set_xlabel('Pixel (X)', fontsize=12)\n",
    "#ax.set_ylabel('Pixel (Y)', fontsize=12)\n",
    "ax.axis('off')\n",
    "ax.grid(False)\n",
    "\n",
    "legend_patches = [mpatches.Patch(color=color, label=label) for label, color in [class_labels[i] for i in range(1, 6)]]\n",
    "ax.legend(handles=legend_patches, loc='lower center', bbox_to_anchor=(0.5, -0.06), ncol=5, fontsize=12, frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f51a070",
   "metadata": {},
   "source": [
    "#### L9 EVALUATION OF CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d522ce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open('data/l9_pred.tif') as src:\n",
    "    class_l9 = src.read(1) \n",
    "    profile = src.profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c568c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_file = 'data/l9_pred.tif'\n",
    "\n",
    "# open just one band with rioxarray\n",
    "class_l9 = rxr.open_rasterio(tiff_file, masked=True).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754708af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_file = 'data/l9_pred.tif'\n",
    "with rxr.open_rasterio(tiff_file, masked=True).squeeze() as class_l9:\n",
    "    class_l9 = class_l9.squeeze()  # remove single-dimensional entries from the shape of an array\n",
    "    print(class_l9.shape)\n",
    "    print(class_l9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ca8a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproject shp to the same CRS as the raster\n",
    "gdf_class_l9 = gdf_imad_l9.to_crs(class_l9.rio.crs)\n",
    "gdf_class_l9.crs == class_l9.rio.crs # check if the CRS is the same\n",
    "\n",
    "# create new column with 19 raster values\n",
    "class_cube = xr.concat(\n",
    "    [class_l9],\n",
    "    dim=pd.Index(\n",
    "        [\"class_l9\"],\n",
    "        name=\"measurement\",\n",
    "    )\n",
    ")\n",
    "class_cube\n",
    "\n",
    "vector_class_cube_l9 = class_cube.drop_vars(\"spatial_ref\").xvec.extract_points(\n",
    "    points=gdf_imad_l9.geometry,\n",
    "    x_coords=\"x\",\n",
    "    y_coords=\"y\",\n",
    ")\n",
    "vector_class_cube_l9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748b3777",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_imad_l9.isna().sum() # check if there are any NaN values in the gdf_imad_l9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4588c31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# landsat 9\n",
    "gdf_class_l9= vector_class_cube_l9.xvec.to_geopandas()\n",
    "print(f'Landsat class 9 data shape:{gdf_class_l9.shape}')\n",
    "\n",
    "# sjoin\n",
    "class_comp_l9 = gdf_class_l9.sjoin(clean_l9_data[['geometry', 'TYPE']], predicate=\"intersects\")\n",
    "# dorp index_right column\n",
    "class_comp_l9.drop(columns=\"index_right\", inplace=True)\n",
    "class_comp_l9 = class_comp_l9.dropna()\n",
    "\n",
    "#clean_l9_data_test - filter test data\n",
    "l9_class_filtered = class_comp_l9.loc[clean_l9_data_test.index]\n",
    "l9_class_filtered.sort_index(inplace=True)\n",
    "l9_class_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c431a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how well the raster classification matches the vector data\n",
    "test_accuracy = accuracy_score(l9_class_filtered['TYPE'], l9_class_filtered['class_l9'])\n",
    "test_error = 1 - test_accuracy\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Error: {test_error:.4f}\")\n",
    "\n",
    "# count producer's accuracy\n",
    "producer_accuracy = l9_class_filtered.groupby('TYPE').apply(lambda x: (x['class_l9'] == x['TYPE']).sum() / len(x))\n",
    "print(\"Producer's Accuracy:\")\n",
    "print(producer_accuracy)\n",
    "# count user's accuracy\n",
    "user_accuracy = l9_class_filtered.groupby('class_l9').apply(lambda x: (x['class_l9'] == x['TYPE']).sum() / len(x))\n",
    "print(\"User's Accuracy:\")\n",
    "print(user_accuracy)\n",
    "# confusion matrix\n",
    "class_names = ['built-up', 'water', 'forests', 'croplands', 'grasslands']\n",
    "l9_c_matrix = confusion_matrix(l9_class_filtered['TYPE'], l9_class_filtered['class_l9'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=l9_c_matrix, display_labels=class_names)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "disp.plot(ax=ax, cmap='Blues', colorbar=False, xticks_rotation=20)\n",
    "plt.title('Confusion Matrix for Landsat 9')\n",
    "plt.show()\n",
    "\n",
    "# classification report\n",
    "report = classification_report(l9_class_filtered['TYPE'], l9_class_filtered['class_l9'], target_names=[str(cls) for cls in np.unique(l9_class_filtered['TYPE'])])\n",
    "print(\"Classification Report for Landsat 9:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39514705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how well the raster classification matches the vector data\n",
    "test_accuracy = accuracy_score(l9_class_filtered['TYPE'], l9_class_filtered['class_l9'])\n",
    "test_error = 1 - test_accuracy\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Error: {test_error:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f66081",
   "metadata": {},
   "source": [
    "### CLASSIFICATION OF NORMALIZED IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1096239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open('data/imad1Itnew_rescale_SWIR.tif') as src: # , data/imad1Itnew_rescale_SWIR.tif, data/imad15Itnew_colab_01.tif, imad10Itnew_colab_01.tif, imad1Itnew_rescale_SWIR.tif\n",
    "    image = src.read()  # tvar: (bands, height, width)\n",
    "    profile = src.profile\n",
    "print(f'image shape: {image.shape}')\n",
    "print(f'profile: {profile}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbedb23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pro Python\n",
    "iamd_selected = image[12:18, :, :] # Landsat 5 bands \n",
    "srtm_selected = image[19:22, :, :] # SRTM, slope, aspect\n",
    "\n",
    "print(f'IMAD bands shape: {iamd_selected.shape}')\n",
    "print(f'SRTM bands shape: {srtm_selected.shape}')\n",
    "#print(f'Indices bands shape: {indices_selected.shape}')\n",
    "iamd_bands = np.concatenate([iamd_selected, srtm_selected], axis=0) #, indices_selected\n",
    "print(f'final_stack shape: {iamd_bands.shape}')\n",
    "\n",
    "# reshape l5, l9 and irmad data for classification\n",
    "reshaped_imad, height_l9, width_l9 = reshape_data(iamd_bands)\n",
    "df_imad = create_dataframe(reshaped_imad)\n",
    "\n",
    "# check the shape of the DataFrames\n",
    "print(f'IRMAD DataFrame shape: {df_imad.shape}')\n",
    "\n",
    "columns_to_replace = ['band_0', 'band_1', 'band_2', 'band_3', 'band_4', 'band_5', 'band_6']\n",
    "nan_mask = df_imad[columns_to_replace].isna()\n",
    "df_imad[columns_to_replace] = df_imad[columns_to_replace].fillna(99999)\n",
    "nan_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7df0947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check values for band_6 and band_7\n",
    "print(f'max val for slope and aspect: \\n{df_imad[['band_7', 'band_8']].max()}')\n",
    "print(f'min val for slope and aspect: \\n{df_imad[['band_7', 'band_8']].min()}')\n",
    "print(f'median val for slope and aspect: \\n{df_imad[['band_7', 'band_8']].median()}')\n",
    "# if band_6 and band_7 are NaN values, set them to 0\n",
    "df_imad['band_7'] = df_imad['band_7'].fillna(0)\n",
    "df_imad['band_8'] = df_imad['band_8'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5785be88",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['l9b', 'l9g', 'l9r', 'l9n', 'l9s1', 'l9s2', 'elevation', 'slope', 'aspect']\n",
    "# rename columns for 'irmad'\n",
    "df_imad.columns = columns\n",
    "# check the shape of the DataFrame\n",
    "df_imad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fabeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating ndvi9,ndmi9, savi9, msavi9, ndbi9, bsi9\n",
    "df_imad['ndvi9'] = ndvi(df_imad['l9r'], df_imad['l9n'])\n",
    "# calculate NDMI for Landsat 9\n",
    "df_imad['ndmi9'] = ndmi(df_imad['l9n'], df_imad['l9s1'])\n",
    "# calculate SAVI for Landsat 9\n",
    "df_imad['savi9'] = savi(df_imad['l9r'], df_imad['l9n'])\n",
    "# calculate MSAVI for Landsat 9\n",
    "df_imad['msavi9'] = msavi(df_imad['l9r'], df_imad['l9n'])\n",
    "# calculate EVI for Landsat 9\n",
    "df_imad['evi9'] = evi(df_imad['l9b'], df_imad['l9r'], df_imad['l9n'])\n",
    "# calculate BSI for Landsat 9\n",
    "df_imad['bsi9'] = bsi(df_imad['l9b'], df_imad['l9r'], df_imad['l9n'], df_imad['l9s1'])\n",
    "df_imad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d71c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSIFICATION OF NORMALIZED IMAGE\n",
    "X_imad = df_imad.values\n",
    "y_pred_imad = l9_model.predict(X_imad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88753a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_raster_imad = y_pred_imad.reshape(height_l9, width_l9).astype(rasterio.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68372fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the prediction raster\n",
    "output_file = 'data/imad_pred_10it_new.tif'\n",
    "with rasterio.open(output_file, 'w', driver='GTiff', height=height_l9, width=width_l9, count=1, dtype=rasterio.uint16, crs=profile['crs'], transform=profile['transform']) as dst:\n",
    "    dst.write(prediction_raster_imad, 1)\n",
    "    dst.update_tags(landcover_type='IMAD', classifier = 'Random Forest', classes='1=Built-up, 2=Water, 3=Forest, 4=Cropland, 5=Grassland')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09074bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(prediction_raster_imad, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f'Class {label}: {count} px')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea4d581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "class_labels = {\n",
    "    1: ('built-up areas', 'red'),    \n",
    "    2: ('water', 'blue'),       \n",
    "    3: ('forests', 'green'),       \n",
    "    4: ('croplands', 'yellow'),     \n",
    "    5: ('grasslands', '#66c2a5')     \n",
    "}\n",
    "pred_crop = prediction_raster_imad[1:-3, 4:-4]\n",
    "\n",
    "cmap_list = [class_labels[i][1] for i in range(1, 6)]\n",
    "cmap = ListedColormap(cmap_list)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "im = ax.imshow(pred_crop, cmap=cmap, interpolation='nearest')\n",
    "ax.set_title('MAD classification', fontsize=16) # IRMAD (5 it.)\n",
    "#ax.set_xlabel('Pixel (X)', fontsize=12)\n",
    "#ax.set_ylabel('Pixel (Y)', fontsize=12)\n",
    "ax.axis('off')\n",
    "ax.grid(False)\n",
    "\n",
    "legend_patches = [mpatches.Patch(color=color, label=label) for label, color in [class_labels[i] for i in range(1, 6)]]\n",
    "ax.legend(handles=legend_patches, loc='lower center', bbox_to_anchor=(0.5, -0.06), ncol=5, fontsize=12, frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcef000",
   "metadata": {},
   "source": [
    "### CLASSIFICATION RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e342a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_file = 'data/imad_pred_1it_new.tif' \n",
    "\n",
    "# open just one band with rioxarray\n",
    "with rxr.open_rasterio(tiff_file, masked=True).squeeze() as class_imad:\n",
    "    class_imad = class_imad.squeeze()  # remove single-dimensional entries from the shape of an array\n",
    "    print(class_imad.shape)\n",
    "    print(class_imad)\n",
    "#class_imad = rxr.open_rasterio(tiff_file, masked=True).squeeze()\n",
    "\n",
    "# create new column with 19 raster values\n",
    "class_imad_cube = xr.concat(\n",
    "    [class_imad],\n",
    "    dim=pd.Index(\n",
    "        [\"class_imad\"],\n",
    "        name=\"measurement\",\n",
    "    )\n",
    ")\n",
    "# class_imad_cube\n",
    "vector_class_cube_imad = class_imad_cube.drop_vars(\"spatial_ref\").xvec.extract_points(\n",
    "    points=gdf_imad_l9.geometry,\n",
    "    x_coords=\"x\",\n",
    "    y_coords=\"y\",\n",
    ")\n",
    "#vector_class_cube_imad\n",
    "\n",
    "# landsat 9\n",
    "gdf_class_imad = vector_class_cube_imad.xvec.to_geopandas()\n",
    "print(f'Landsat class 9 data shape:{gdf_class_l9.shape}')\n",
    "# sjoin - prepared databefore filtering\n",
    "class_comp_imad = gdf_class_imad.sjoin(l9_data[['geometry', 'TYPE']], predicate=\"intersects\") # clean_l9_data_test\n",
    "# dorp index_right column\n",
    "class_comp_imad.drop(columns=\"index_right\", inplace=True)\n",
    "class_comp_imad = class_comp_imad.dropna()\n",
    "\n",
    "#clean_l9_data_test - filtered test data with geometry prepared for comparison\n",
    "imad_class_filtered = class_comp_imad.loc[clean_l9_data_test.index] # \n",
    "imad_class_filtered.sort_index(inplace=True)\n",
    "imad_class_filtered.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f952685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how well the raster classification matches the vector data\n",
    "test_accuracy = accuracy_score(imad_class_filtered['TYPE'], imad_class_filtered['class_imad'])\n",
    "test_error = 1 - test_accuracy\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Error: {test_error:.4f}\")\n",
    "\n",
    "# count producer's accuracy\n",
    "producer_accuracy = imad_class_filtered.groupby('TYPE').apply(lambda x: (x['class_imad'] == x['TYPE']).sum() / len(x))\n",
    "print(\"Producer's Accuracy:\")\n",
    "print(producer_accuracy)\n",
    "# count user's accuracy\n",
    "user_accuracy = imad_class_filtered.groupby('class_imad').apply(lambda x: (x['class_imad'] == x['TYPE']).sum() / len(x))\n",
    "print(\"User's Accuracy:\")\n",
    "print(user_accuracy)\n",
    "# confusion matrix\n",
    "class_names = ['built-up', 'water', 'forests', 'croplands', 'grasslands']\n",
    "l9_c_matrix = confusion_matrix(imad_class_filtered['TYPE'], imad_class_filtered['class_imad'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=l9_c_matrix, display_labels=class_names)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "disp.plot(ax=ax, cmap='Blues', colorbar=False, xticks_rotation=20)\n",
    "plt.title('Confusion Matrix for MAD') # IRMAD (5 it.) X MAD\n",
    "plt.show()\n",
    "# classification report\n",
    "report = classification_report(imad_class_filtered['TYPE'], imad_class_filtered['class_imad'])\n",
    "print(\"Classification Report for IMAD:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fa8611",
   "metadata": {},
   "source": [
    "### Ověření na Landsat 5\n",
    " - pokud budou výsledky klasifikace Landsat 5 na modelu z roku 2023 horší než u IRMAD lze považovat za úspěch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5399201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Landsat 5 bands\n",
    "landsat5_selected = image[6:12, :, :] # Landsat 5 bands \n",
    "srtm_selected = image[19:22, :, :] # SRTM, slope, aspect\n",
    "\n",
    "print(f'Landsat 5 bands shape: {landsat5_selected.shape}')\n",
    "print(f'SRTM bands shape: {srtm_selected.shape}')\n",
    "#print(f'Indices bands shape: {indices_selected.shape}')\n",
    "landsat5_bands = np.concatenate([landsat5_selected, srtm_selected], axis=0) #, indices_selected\n",
    "print(f'final_stack shape: {landsat5_bands.shape}')\n",
    "\n",
    "reshaped_l5, height_l9, width_l9= reshape_data(landsat5_bands)\n",
    "df_l5 = create_dataframe(reshaped_l5)\n",
    "print(f'Landsat 5 DataFrame shape: {df_l5.shape}')\n",
    "\n",
    "columns_to_replace = ['band_0', 'band_1', 'band_2', 'band_3', 'band_4', 'band_5', 'band_6']\n",
    "nan_mask = df_l5[columns_to_replace].isna()\n",
    "df_l5[columns_to_replace] = df_l5[columns_to_replace].fillna(99999)\n",
    "nan_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c01753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check values for band_6 and band_7\n",
    "print(f'max val for slope and aspect: \\n{df_l5[['band_7', 'band_8']].max()}')\n",
    "print(f'min val for slope and aspect: \\n{df_l5[['band_7', 'band_8']].min()}')\n",
    "print(f'median val for slope and aspect: \\n{df_l5[['band_7', 'band_8']].median()}')\n",
    "# if band_6 and band_7 are NaN values, set them to 0\n",
    "df_l5['band_7'] = df_l5['band_7'].fillna(0)\n",
    "df_l5['band_8'] = df_l5['band_8'].fillna(0)\n",
    "\n",
    "columns = ['l9b', 'l9g', 'l9r', 'l9n', 'l9s1', 'l9s2', 'elevation', 'slope', 'aspect']\n",
    "# features for classification need to be the same as for Landsat 9 model\n",
    "df_l5.columns = columns\n",
    "df_l5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6677fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating ndvi9,ndmi9, savi9, msavi9, ndbi9, bsi9 - but for landsat 5 \n",
    "# features for classification need to be the same as for Landsat 9 model\n",
    "df_l5['ndvi9'] = ndvi(df_l5['l9r'], df_l5['l9n'])\n",
    "df_l5['ndmi9'] = ndmi(df_l5['l9n'], df_l5['l9s1'])\n",
    "df_l5['savi9'] = savi(df_l5['l9r'], df_l5['l9n'])\n",
    "df_l5['msavi9'] = msavi(df_l5['l9r'], df_l5['l9n'])\n",
    "df_l5['evi9'] = evi(df_l5['l9b'], df_l5['l9r'], df_l5['l9n'])\n",
    "df_l5['bsi9'] = bsi(df_l5['l9b'], df_l5['l9r'], df_l5['l9n'], df_l5['l9s1'])\n",
    "df_l5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a12f388",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_l5 = df_l5.values\n",
    "y_pred_l5 = l9_model.predict(X_l5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45bf702",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_raster_l5 = y_pred_l5.reshape(height_l9, width_l9).astype(rasterio.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40fe276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save classification\n",
    "# save the prediction raster\n",
    "output_file = 'data/l5_pred_new.tif'\n",
    "with rasterio.open(output_file, 'w', driver='GTiff', height=height_l9, width=width_l9, count=1, dtype=rasterio.uint16, crs=profile['crs'], transform=profile['transform']) as dst:\n",
    "    dst.write(prediction_raster_l5, 1)\n",
    "    dst.update_tags(landcover_type='Landsat 9', classifier = 'Random Forest', classes='1=Built-up, 2=Water, 3=Forest, 4=Cropland, 5=Grassland') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e161d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(prediction_raster_l5, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f'Class {label}: {count} px')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f53aebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = {\n",
    "    1: ('built-up areas', 'red'),    \n",
    "    2: ('water', 'blue'),       \n",
    "    3: ('forests', 'green'),       \n",
    "    4: ('croplands', 'yellow'),     \n",
    "    5: ('grasslands', '#66c2a5')     \n",
    "}\n",
    "pred_crop = prediction_raster_l5[1:-3, 4:-4]\n",
    "cmap_list = [class_labels[i][1] for i in range(1, 6)]\n",
    "cmap = ListedColormap(cmap_list)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "im = ax.imshow(pred_crop, cmap=cmap, interpolation='nearest') # \n",
    "ax.set_title('Landsat 5 classification (according to the Landsat 9 model)', fontsize=16)\n",
    "#ax.set_xlabel('Pixel (X)', fontsize=12)\n",
    "#ax.set_ylabel('Pixel (Y)', fontsize=12)\n",
    "ax.grid(False)\n",
    "ax.axis('off')\n",
    "\n",
    "legend_patches = [mpatches.Patch(color=color, label=label) for label, color in [class_labels[i] for i in range(1, 6)]]\n",
    "ax.legend(handles=legend_patches, loc='lower center', bbox_to_anchor=(0.5, -0.06), ncol=5, fontsize=12, frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f69d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_file = 'data/l5_pred_new.tif' \n",
    "\n",
    "with rxr.open_rasterio(tiff_file, masked=True).squeeze() as class_imad:\n",
    "    class_imad = class_imad.squeeze()  # remove single-dimensional entries from the shape of an array\n",
    "    print(class_imad.shape)\n",
    "    print(class_imad)\n",
    "# create new column with 19 raster values\n",
    "class_imad_cube = xr.concat(\n",
    "    [class_imad],\n",
    "    dim=pd.Index(\n",
    "        [\"class_imad\"],\n",
    "        name=\"measurement\",\n",
    "    )\n",
    ")\n",
    "# gdf_class_l5 to same CRS as class_imad \n",
    "gdf_class_l5 = gdf_imad_l9.to_crs(class_imad.rio.crs)\n",
    "\n",
    "# class_imad_cube\n",
    "vector_class_cube_imad = class_imad_cube.drop_vars(\"spatial_ref\").xvec.extract_points(\n",
    "    points=gdf_class_l5.geometry, \n",
    "    x_coords=\"x\",\n",
    "    y_coords=\"y\",\n",
    ")\n",
    "\n",
    "gdf_class_imad = vector_class_cube_imad.xvec.to_geopandas()\n",
    "print(f'Landsat class 5 data shape:{gdf_class_l5.shape}')\n",
    "# sjoin\n",
    "class_comp_imad = gdf_class_imad.sjoin(gdf_class_l5[['geometry', 'TYPE']], predicate=\"intersects\")\n",
    "# dorp index_right column\n",
    "class_comp_imad.drop(columns=\"index_right\", inplace=True)\n",
    "class_comp_imad = class_comp_imad.dropna()\n",
    "\n",
    "#clean_l9_data_test\n",
    "imad_class_filtered = class_comp_imad.loc[clean_l9_data_test.index] # \n",
    "imad_class_filtered.sort_index(inplace=True)\n",
    "imad_class_filtered.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473aed61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how well the raster classification matches the vector data - tady porovnáno na všech datech včetně trénovací množiny\n",
    "test_accuracy = accuracy_score(imad_class_filtered['TYPE'], imad_class_filtered['class_imad'])\n",
    "test_error = 1 - test_accuracy\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Error: {test_error:.4f}\")\n",
    "\n",
    "# count producer's accuracy\n",
    "producer_accuracy = imad_class_filtered.groupby('TYPE').apply(lambda x: (x['class_imad'] == x['TYPE']).sum() / len(x))\n",
    "print(\"Producer's Accuracy:\")\n",
    "print(producer_accuracy)\n",
    "# count user's accuracy\n",
    "user_accuracy = imad_class_filtered.groupby('class_imad').apply(lambda x: (x['class_imad'] == x['TYPE']).sum() / len(x))\n",
    "print(\"User's Accuracy:\")\n",
    "print(user_accuracy)\n",
    "# confusion matrix\n",
    "class_names = ['built-up', 'water', 'forests', 'croplands', 'grasslands']\n",
    "l9_c_matrix = confusion_matrix(imad_class_filtered['TYPE'], imad_class_filtered['class_imad'])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=l9_c_matrix, display_labels=class_names)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "disp.plot(ax=ax, cmap='Blues', colorbar=False, xticks_rotation=20)\n",
    "plt.title('Confusion Matrix for Landsat 5')\n",
    "plt.show()\n",
    "# classification report\n",
    "report = classification_report(imad_class_filtered['TYPE'], imad_class_filtered['class_imad'])\n",
    "print(\"Classification Report for Landsat 5:\")\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
